{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"detection_boxes:0\", dtype=float32)\n",
      "Fps: 11.98\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils_color as vis_util\n",
    "from imutils.video import FPS\n",
    "from imutils.video import WebcamVideoStream\n",
    "\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = './model/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = './proto/label_map.pbtxt'\n",
    "\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "# Loading label map\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "\n",
    "def face_detection():\n",
    "\n",
    "    # Load Tensorflow model\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.compat.v1.GraphDef()\n",
    "        with tf.compat.v2.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "        sess = tf.Session(graph=detection_graph)\n",
    "\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    print(detection_boxes)\n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "\n",
    "    # Actual detection.\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    # Start video stream\n",
    "    cap = WebcamVideoStream(0).start()\n",
    "    fps = FPS().start()\n",
    "\n",
    "    while True:\n",
    "\n",
    "        frame = cap.read()\n",
    "\n",
    "        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "        expanded_frame = np.expand_dims(frame, axis=0)\n",
    "        (boxes, scores, classes, num_c) = sess.run(\n",
    "            [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "            feed_dict={image_tensor: expanded_frame})\n",
    "        # Visualization of the detection\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            frame,\n",
    "            np.squeeze(boxes),\n",
    "            np.squeeze(classes).astype(np.int32),\n",
    "            np.squeeze(scores),\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=2,\n",
    "            min_score_thresh=0.40)\n",
    "\n",
    "        cv2.imshow('Detection', frame)\n",
    "        fps.update()\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            fps.stop()\n",
    "            break\n",
    "        \n",
    "\n",
    "    print(\"Fps: {:.2f}\".format(fps.fps()))\n",
    "    fps.update()\n",
    "    cap.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    face_detection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 14:27:46.244503: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"detection_boxes:0\", dtype=float32)\n",
      "836 371 566 999\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/admin/Downloads/Tensorflow-face-detection-master/main.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 155>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/admin/Downloads/Tensorflow-face-detection-master/main.ipynb#ch0000001?line=151'>152</a>\u001b[0m     cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/admin/Downloads/Tensorflow-face-detection-master/main.ipynb#ch0000001?line=154'>155</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/admin/Downloads/Tensorflow-face-detection-master/main.ipynb#ch0000001?line=155'>156</a>\u001b[0m     face_detection()\n",
      "\u001b[1;32m/Users/admin/Downloads/Tensorflow-face-detection-master/main.ipynb Cell 2'\u001b[0m in \u001b[0;36mface_detection\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/admin/Downloads/Tensorflow-face-detection-master/main.ipynb#ch0000001?line=104'>105</a>\u001b[0m output \u001b[39m=\u001b[39m process_face(frame)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/admin/Downloads/Tensorflow-face-detection-master/main.ipynb#ch0000001?line=105'>106</a>\u001b[0m roi \u001b[39m=\u001b[39m output[x:x\u001b[39m+\u001b[39mw,y:y\u001b[39m+\u001b[39mh]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/admin/Downloads/Tensorflow-face-detection-master/main.ipynb#ch0000001?line=106'>107</a>\u001b[0m roi_gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(roi, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2RGB)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/admin/Downloads/Tensorflow-face-detection-master/main.ipynb#ch0000001?line=108'>109</a>\u001b[0m     \u001b[39m# Mask is boolean type of matrix.\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/admin/Downloads/Tensorflow-face-detection-master/main.ipynb#ch0000001?line=109'>110</a>\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros_like(roi_gray)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils_color as vis_util\n",
    "from imutils.video import FPS\n",
    "from imutils.video import WebcamVideoStream\n",
    "\n",
    "TEMP_TUNER = 1.80\n",
    "TEMP_TOLERENCE = 70.6\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = './model/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = './proto/label_map.pbtxt'\n",
    "\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "# Loading label map\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "def convert_to_temperature(pixel_avg):\n",
    "    \"\"\"\n",
    "    Converts pixel value (mean) to temperature depending upon the camera hardware\n",
    "    \"\"\"\n",
    "    f = pixel_avg / TEMP_TUNER\n",
    "    c = (f - 32) * 5/9\n",
    "\n",
    "    \n",
    "    return f\n",
    "\n",
    "def process_face(frame):\n",
    "    frame = frame\n",
    "    heatmap = frame\n",
    "    \n",
    "    heatmap_gray = cv2.cvtColor(heatmap, cv2.COLOR_RGB2GRAY)\n",
    "    ret, binary_thresh = cv2.threshold(heatmap_gray, 200, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    image_erosion = cv2.erode(binary_thresh, kernel, iterations=1)\n",
    "    image_opening = cv2.dilate(image_erosion, kernel, iterations=1)\n",
    "    \n",
    "\n",
    "    image_with_rectangles = np.copy(heatmap)\n",
    "    \n",
    "    return image_with_rectangles\n",
    "def face_detection():\n",
    "    \n",
    "    # Load Tensorflow model\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.compat.v1.GraphDef()\n",
    "        with tf.compat.v2.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "        sess = tf.Session(graph=detection_graph)\n",
    "\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    print(detection_boxes)\n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "\n",
    "    # Actual detection.\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    # Start video stream\n",
    "    cap = WebcamVideoStream(0).start()\n",
    "    fps = FPS().start()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    frame_height = int(cap.get(3))\n",
    "    frame_width = int(cap.get(4))\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 180)\n",
    "        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "        expanded_frame = np.expand_dims(frame, axis=0)\n",
    "        (boxes, scores, classes, num_c) = sess.run(\n",
    "            [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "            feed_dict={image_tensor: expanded_frame})\n",
    "\n",
    "        width = frame_width\n",
    "        height = frame_height\n",
    "\n",
    "        i = 1\n",
    "        y = int(boxes[0][i][0]*width)\n",
    "        x = int(boxes[0][i][1]*height)\n",
    "        h = int(boxes[0][i][2]*height)\n",
    "        w = int(boxes[0][i][3]*width)\n",
    "        print(x,y,w,h)\n",
    "        output = process_face(frame)\n",
    "        roi = output[x:x+w,y:y+h]\n",
    "        roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Mask is boolean type of matrix.\n",
    "        mask = np.zeros_like(roi_gray)\n",
    "\n",
    "        # Mean of only those pixels which are in blocks and not the whole rectangle selected\n",
    "        mean = convert_to_temperature(np.mean(roi_gray))\n",
    "\n",
    "        # Colors for rectangles and textmin_area\n",
    "        temperature = round(mean, 2)\n",
    "        color = (0, 255, 0) if temperature < TEMP_TOLERENCE else (\n",
    "            255, 255, 255)\n",
    "        \n",
    "\n",
    "        # Draw rectangles for visualisation\n",
    "        output = cv2.rectangle(output, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(output, \"{} C\".format(temperature), (x, y-5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)\n",
    "        if temperature > 110:\n",
    "            print(\"image captured\")\n",
    "            cv2.imwrite(filename='saved_img.jpg', img=frame)\n",
    "            '''cap.release()\n",
    "            img_new = cv2.imread('saved_img.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "            img_new = cv2.imshow(\"Captured Image\", img_new)\n",
    "            cv2.waitKey(1650)\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"Processing image...\")\n",
    "            img_ = cv2.imread('saved_img.jpg', cv2.IMREAD_ANYCOLOR)\n",
    "            print(\"Converting RGB image to grayscale...\")\n",
    "            gray = cv2.cvtColor(img_, cv2.COLOR_BGR2GRAY)\n",
    "            print(\"Converted RGB image to grayscale...\")\n",
    "            print(\"Resizing image to 28x28 scale...\")\n",
    "            print(\"Resized...\")\n",
    "            img_resized = cv2.imwrite(filename='saved_img-final.jpg', img=gray)'''\n",
    "\n",
    "        \n",
    "        cv2.imshow('Thermal', output)\n",
    "            # out.write(output)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    # out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    face_detection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fps: 7.62\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils_color as vis_util\n",
    "from imutils.video import FPS\n",
    "from imutils.video import WebcamVideoStream\n",
    "\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = './model/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = './proto/label_map.pbtxt'\n",
    "\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "# Loading label map\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "\n",
    "def face_detection():\n",
    "\n",
    "    # Load Tensorflow model\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.compat.v1.GraphDef()\n",
    "        with tf.compat.v2.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "        sess = tf.Session(graph=detection_graph)\n",
    "\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "\n",
    "    # Actual detection.\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    frame_height = int(cap.get(3))\n",
    "    frame_width = int(cap.get(4))\n",
    "    # Start video stream\n",
    "    cap = WebcamVideoStream(0).start()\n",
    "    fps = FPS().start()\n",
    "\n",
    "    while True:\n",
    "\n",
    "        frame = cap.read()\n",
    "        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "        expanded_frame = np.expand_dims(frame, axis=0)\n",
    "        (boxes, scores, classes, num_c) = sess.run(\n",
    "            [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "            feed_dict={image_tensor: expanded_frame})\n",
    "            \n",
    "        # Visualization of the detection\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            frame,\n",
    "            np.squeeze(boxes),\n",
    "            np.squeeze(classes).astype(np.int32),\n",
    "            np.squeeze(scores),\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=2,\n",
    "            min_score_thresh=0.40)\n",
    "\n",
    "        cv2.imshow('Detection', frame)\n",
    "        fps.update()\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            fps.stop()\n",
    "            break\n",
    "        \n",
    "\n",
    "    print(\"Fps: {:.2f}\".format(fps.fps()))\n",
    "    fps.update()\n",
    "    cap.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    face_detection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0202325955"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.02325955e-02"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
